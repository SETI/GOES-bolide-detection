#!/usr/bin/env python

# This function is used to package the figures generated by the bolide detection pipeline and the ABI cutout tool into
# data sets to vetting by the bolide experts.
# 
# Things to package up:
# 1) Combine the detection and cutout figures into a single png file
# 2) Copy over the PNG to the pipeline outputs directory
# 3) If the outputs directory is not the same as the detection directory then also copy over the .nc files
#
# A history file is used to track which days have been packaged.  
#
# Run this on each GOES satellite seperately (just like the pipeline)
#
# In normal operation the pipeline will generate the PDF reports and this module is not used.



import time
import sys
import os
import glob
import shutil
from PIL import Image
from datetime import date

import io_utilities as ioUtil
import bolide_database as bolideDB

def get_configuration_template():
    """ Retrieve a dictionary defining configuration parameter names, data types, and
    default values.

    Initialize the configuration dictionary with parameter names and their
    associated types. Values read from the file will be cast to the specified
    type.

    Nomincally, the output directory is the detecrionRootDir. If you wish a different output directory then set
    outputDir to a path, if empty then set to detectionRootDir.
    """

    #                   parameter                      type    default
    configTemplate = {'detectionRootDir':           ['str', '.'],
                      'cutoutRootDir':              ['str', '.'],
                      'outputDir':                  ['str', ''],
                      'packagingHistoryBaseName':   ['str', 'packaging_history'],
                      'processingHistoryBaseName':  ['str', 'processing_history'],
                      'forceReprocess':             ['bool', False],
                      'createSymlinks':             ['bool', True],
                      'startDate':                  ['str', ''],
                      'endDate':                    ['str', ''],
                      'verbosity':                  ['bool', True]
                      }

    return configTemplate

#*************************************************************************************************************
def set_diff(first, second):
    """ Return elements in first set that are not in second.

    Returns
    -------
    set_diff_list -- elements in first set that are not in second.
    idx_in_first  -- Indices of kept elements in first
    """

    zippedList = [[idx, item] for idx, item in enumerate(first) if item not in second]
    set_diff_list = [j for [i,j] in zippedList]
    idx_in_first = [i for [i,j] in zippedList]

    return set_diff_list, idx_in_first 

#*************************************************************************************************************
def merge_images(fileLeft, fileRight, saveFilename):
    """ Merges two images into a single image and saves to file.

    Image2 is resized to that of image1.

    Parameters
    ----------
    fileLeft   :   str
        Filename for the file to be placed on the left
    fileRight   :   str
        Filename for the file to be placed on the right
        This image can be None, if so then a blank image is merged
    saveFilename : str
        Filename to save the merged figure

    Returns
    -------
    Just a saved file

    """

    # Read the two images
    image1 = Image.open(fileLeft)
    image1_size = image1.size

    if (fileRight is not None):
        image2 = Image.open(fileRight)
        # Resize image2 to be equal to image1
        image2 = image2.resize(image1_size)
        image2_size = image2.size
    else:
        image2 = None

    new_image = Image.new('RGB',(2*image1_size[0], image1_size[1]), (250,250,250))
    new_image.paste(image1,(0,0))
    if image2 is not None:
        new_image.paste(image2,(image1_size[0],0))

    new_image.save(saveFilename,"PNG")

    
#*************************************************************************************************************
def package_figures_and_copy(detectionDirPath, cutoutDayDirPath, output_path, createSymlinks, verbosity):
    """ Searches for detection figures, finds the cutout figures and combines.

    The combined figure is saved in the given output directory.

    Other figures and netCDF files are also copied over to the output directory.

    Parameters
    ----------
    detectionDirPath : str
        Path to detection figures
    cutoutDayDirPath : str
        Path to cutout figures
    output_path : str
        Path to where to save the merged figures
    createSymlinks : bool
        When copying over the netCDF files and stereo detection figures, make a copy or create symlink
    verbosity : bool
        To be or not to be verbose

    Returns
    -------
    figures and netCDF files store din output_path

    """


    # Go through each detection in the day directory and find the corresponding cutout figure
    # We could read in the database to get the information we need but the pipeline should have already generated
    # the png figures so we just need to go through each figure already generated
    # The desired figures either end  with '_detection.png' or '_otherSatellite_detection.png'
    detectionFilenameList = glob.glob(os.path.join(detectionDirPath, '*_detection.png'))

    stereoDetections = glob.glob(os.path.join(detectionDirPath, '*_stereo.png'))
    ioUtil.create_path(output_path, verbosity)

    for detection in detectionFilenameList:
        # Get the detection ID
        # It's at the end of the detection figure filename
        # It's right before the _detection.png
        # Or right before the '_otherSatellite'
        IDidx = os.path.splitext(detection)[0].index('_detection')
        ID = os.path.splitext(detection)[0][-19+IDidx:IDidx]
        if not bolideDB.check_valid_ID(ID):
            # See if this is an "other satellite" figure
            try:
                IDidx = os.path.splitext(detection)[0].index('_otherSatellite')
                ID = os.path.splitext(detection)[0][-19+IDidx:IDidx]
                # Did we get a legitimate ID?
                if not bolideDB.check_valid_ID(ID):
                    continue
            except:
                continue

        # Find the cutout figure
        availableCutouts = glob.glob(os.path.join(cutoutDayDirPath, '*.png'))
        availableCutouts = [figure for figure in availableCutouts if figure.count('ABI') > 0]
        # Only keep ABI figures
        index = [idx for idx,filename in enumerate(availableCutouts) if os.path.split(filename)[1][0:19].count(ID) > 0]
        if (len(index) > 1): 
            raise Exception('Found multiple cutout figures with same detection ID: {}'.format(ID))
        elif (len(index) == 0):
            # No cutout available
            cutoutFile = None
        else:
            cutoutFile = availableCutouts[index[0]]

        merged_filename = os.path.split(detection)[1]
        split_filename = os.path.splitext(merged_filename)
        merged_filename = split_filename[0] + '_with_cutout' + split_filename[1]
        merge_images(detection, cutoutFile, os.path.join(output_path,merged_filename))

    # If output_path is not the same as detectionDirPath then copy or symlink over the .nc files.
    if output_path != detectionDirPath:
        availableNetCdfFiles = glob.glob(os.path.join(detectionDirPath, '*.nc'))
        ioUtil.copy_or_create_symlinks(availableNetCdfFiles, output_path, createSymlinks, verbosity)

        # Copy over the stereo detection images (which do not pair with cutout figures)
        ioUtil.copy_or_create_symlinks(stereoDetections, output_path, createSymlinks, verbosity)



if __name__ == "__main__":
    """ Used to call packager from command line

    Ussually, the 

    A single command line arguments gives the path to the configuration file.

    """

    startTime = time.time()

    config = ioUtil.read_config_file(sys.argv[1], configTemplate=get_configuration_template())
    detectionRootDir    = config['detectionRootDir']
    cutoutRootDir       = config['cutoutRootDir']
    outputDir           = config['outputDir']
    packagingHistoryBaseName    = config['packagingHistoryBaseName']
    processingHistoryBaseName   = config['processingHistoryBaseName']
    forceReprocess      = config['forceReprocess']
    createSymlinks      = config['createSymlinks']
    startDate           = config['startDate']
    endDate             = config['endDate']
    verbosity           = config['verbosity']
    if outputDir == '':
        outputDir = detectionRootDir


    # If forcing reprocessing then delete the packaging history log file
    packagingHistoryPath = os.path.join(detectionRootDir, packagingHistoryBaseName + '.txt')
    if (forceReprocess):
        if (outputDir != detectionRootDir):
            # If seperate output directory then delete everything
            if os.path.exists(outputDir):
                shutil.rmtree(outputDir)
        # Also delete the plackaging history file in the detection output path
        if os.path.exists(packagingHistoryPath):
            os.remove(packagingHistoryPath)

    #***********
    # Generate list of days which need to be processed

    #***
    # List of detection days available
    # We find this by looking at the detection processing history file
    processingHistoryPath = os.path.join(detectionRootDir, processingHistoryBaseName + '.txt')
    processedFileDayList = []
    processedFileNameList = []
    if os.path.isfile(processingHistoryPath):
        for line in open(processingHistoryPath).readlines():
        
            # Strip out comments and lines containing only whitespace.
            s = line.split(sep='#', maxsplit=2)[0]
            s = ''.join(s.split())  # Remove all whitespace.
            # Only keep the date stamp
            s = line.split(sep=' ', maxsplit=2)[0]
            filename = line.split(sep=' ', maxsplit=2)[1]
            if len(s.strip()) <= 0:  # if s is empty, get the next line.
                continue
        
            processedFileDayList.append(s)
            processedFileNameList.append(filename)

    #***
    # List of days already processed files
    packagedFileList = []
    if os.path.isfile(packagingHistoryPath):
        for line in open(packagingHistoryPath).readlines():

            # Strip out comments and lines containing only whitespace.
            s = line.split(sep='#', maxsplit=2)[0]
            s = ''.join(s.split())  # Remove all whitespace.
            # Only keep the date stamp
            s = line.split(sep=' ', maxsplit=2)[0]
            if len(s.strip()) <= 0:  # if s is empty, get the next line.
                continue
        
            packagedFileList.append(s)

    # Identify days to process.
    processedSet   = set(processedFileDayList)
    packagedSet   = set(packagedFileList)
    [daysToPackage, idx_in_list] = set_diff(processedSet, packagedSet)
    processedFileNameList = [processedFileNameList[idx] for idx in idx_in_list]

    print('Processed files: {}'.format(len(processedSet)))
    print('Packaged files: {}'.format(len(packagedSet)))

    # Only include files within the requested processing dates
    if ((startDate != '' and startDate is not None) or
        (endDate   != '' and endDate   is not None)):

        if startDate == '' or startDate is None:
            startDate = date.min
        else:
            startDate = date.fromisoformat(startDate)

        if endDate == '' or endDate is None:
            endDate = date.max
        else:
            endDate = date.fromisoformat(endDate)

        print('Only processing data between {} and {}'.format(startDate, endDate))

        # Get dates from daysToPackage filename
        # Daily bundle files have names like: OR_GLM-L2-LCFA_G16_s20191220.nc.tgz
        # So, search for _s*.tgz
        fileIndicesToKeep = []

        for fileListIdx, dayString in enumerate(daysToPackage):
            year    = int(dayString[0:4])
            month   = int(dayString[5:7])
            day     = int(dayString[8:10])
            thisFileDate = date(year, month, day)
            if thisFileDate >= startDate and thisFileDate <= endDate:
                # Within date range, add to list to keep
                fileIndicesToKeep.append(fileListIdx)

        daysToPackage = [daysToPackage[idx] for idx in fileIndicesToKeep]
        processedFileNameList = [processedFileNameList[idx] for idx in fileIndicesToKeep]

    print('Days to package: {}'.format(len(daysToPackage)))

    
    # Check to see whether the output directory exists and create it if necessary.
    ioUtil.create_path(outputDir, verbosity)

    #***********
    # Go through each day and merge the cutout figure with the detection figure
    for dayIdx, dayToProcess in enumerate(daysToPackage):

        # Get year and date
        year = dayToProcess[0:4]
        monthDay = dayToProcess[5:7] + dayToProcess[8:10]
        
        output_path = os.path.join(outputDir,year,monthDay)

        detectionDirPath = os.path.join(detectionRootDir,year,monthDay)
        cutoutDayDirPath = os.path.join(cutoutRootDir,year,monthDay)

        package_figures_and_copy(detectionDirPath, cutoutDayDirPath, output_path, createSymlinks, verbosity)

        # Update the packaging history file.
        dirName = processedFileNameList[dayIdx]
        ISODate = dayToProcess
        log_entry = ISODate + ' ' + dirName[0:-1]
        if not ioUtil.append_lines_to_file(packagingHistoryPath, [log_entry]):
            raise Exception('Error updating packaging history file.')

        # Make sure all output directories and files are world readable
        # Note: os.chmod expects mode to be an octal number, so prepend with '0o'
        os.chmod(outputDir, 0o755)
        os.chmod(os.path.join(outputDir, monthDay), 0o755)
        os.chmod(output_path, 0o755)
        # All files in subdirectory
        for name in glob.glob(output_path+'/*'):
            os.chmod(name, 0o644)

    
    endTime = time.time()
    totalTime = endTime - startTime
    print("")
    print("****** package_bolide_detections successfuly finished")
    print("")
    print("Total processing time: {:.2f} seconds, {:.2f} minutes".format(totalTime, totalTime/60))
    print("")

